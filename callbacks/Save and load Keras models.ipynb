{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Save and load Keras models.ipynb","provenance":[],"authorship_tag":"ABX9TyP90hrTQG4FkYTc6xlHQmQ1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"lTwoeBzAUio3"},"source":["https://colab.research.google.com/github/tensorflow/docs/blob/snapshot-keras/site/en/guide/keras/save_and_serialize.ipynb"]},{"cell_type":"markdown","metadata":{"id":"47zKRTpETZ6H"},"source":["# **Introduction**"]},{"cell_type":"markdown","metadata":{"id":"7k1w88cbUXp9"},"source":["A Keras model consists of multiple components:\n","\n","The architecture, or configuration, which specifies what layers the model contain, and how they're connected.\n","\n","A set of weights values (the \"state of the model\").\n","\n","An optimizer (defined by compiling the model).\n","\n","A set of losses and metrics (defined by compiling the model or calling add_loss() or add_metric()).\n","\n","The Keras API makes it possible to save all of these pieces to disk at once, or to only selectively save some of them:\n","\n","Saving everything into a single archive in the TensorFlow SavedModel format (or in the older Keras H5 format). This is the standard practice.\n","\n","Saving the architecture / configuration only, typically as a JSON file.\n","\n","Saving the weights values only. This is generally used when training the model."]},{"cell_type":"markdown","metadata":{"id":"pxXnWSsNU1gV"},"source":["**Saving a Keras model:**"]},{"cell_type":"code","metadata":{"id":"X1ZRbR3DS4bt"},"source":["model = ...  # Get model (Sequential, Functional Model, or Model subclass)\n","model.save('path/to/location')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oIHKXoG5U3gl"},"source":["**Loading the model back:**"]},{"cell_type":"code","metadata":{"id":"xtpwzo-RU7R4"},"source":["from tensorflow import keras\n","model = keras.models.load_model('path/to/location')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D6U4JTJdVHR2","executionInfo":{"status":"ok","timestamp":1617798935218,"user_tz":-330,"elapsed":3629,"user":{"displayName":"aayush jain","photoUrl":"","userId":"06466801638325838312"}}},"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xwFFeGQDVLnX"},"source":["# **Whole-model saving & loading**"]},{"cell_type":"markdown","metadata":{"id":"P2M7sRewVT_Q"},"source":["You can save an entire model to a single artifact. It will include:\n","\n","The model's architecture/config\n","\n","The model's weight values (which were learned during training)\n","\n","The model's compilation information (if compile() was called)\n","\n","The optimizer and its state, if any (this enables you to restart training where you left)"]},{"cell_type":"markdown","metadata":{"id":"W6InFIIIVezc"},"source":["# **APIs**\n","1.model.save() or tf.keras.models.save_model()\n","\n","2.tf.keras.models.load_model()\n","\n","There are two formats you can use to save an entire model to disk: the **TensorFlow SavedModel format**, and the **older Keras H5 format**. **The recommended format is SavedModel. It is the default when you use model.save()**.\n","\n","**You can switch to the H5 format by:**\n","\n","Passing save_format='h5' to save().\n","\n","Passing a filename that ends in .h5 or .keras to save()."]},{"cell_type":"markdown","metadata":{"id":"KHJAuTLAWS7m"},"source":["# **SavedModel format**"]},{"cell_type":"markdown","metadata":{"id":"TIJb1sjRWoKG"},"source":["SavedModel is the more comprehensive save format that saves the model architecture, weights, and the traced Tensorflow subgraphs of the call functions. This enables Keras to restore both built-in layers as well as custom objects."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OzaetQFPVHvU","executionInfo":{"status":"ok","timestamp":1617799538862,"user_tz":-330,"elapsed":3757,"user":{"displayName":"aayush jain","photoUrl":"","userId":"06466801638325838312"}},"outputId":"90fa52b9-404b-4a12-c59f-7bfa774c7a91"},"source":["def get_model():\n","    # Create a simple model.\n","    inputs = keras.Input(shape=(32,))\n","    outputs = keras.layers.Dense(1)(inputs)\n","    model = keras.Model(inputs, outputs)\n","    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n","    return model\n","\n","\n","model = get_model()\n","\n","# Train the model.\n","test_input = np.random.random((128, 32))\n","test_target = np.random.random((128, 1))\n","model.fit(test_input, test_target)\n","\n","# Calling `save('my_model')` creates a SavedModel folder `my_model`.\n","model.save(\"my_model\")\n","\n","# It can be used to reconstruct the model identically.\n","reconstructed_model = keras.models.load_model(\"my_model\")\n","\n","# Let's check:\n","np.testing.assert_allclose(\n","    model.predict(test_input), reconstructed_model.predict(test_input)\n",")\n","\n","# The reconstructed model is already compiled and has retained the optimizer\n","# state, so training can resume:\n","reconstructed_model.fit(test_input, test_target)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["4/4 [==============================] - 1s 3ms/step - loss: 0.8465\n","INFO:tensorflow:Assets written to: my_model/assets\n","4/4 [==============================] - 0s 3ms/step - loss: 0.7066\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7ff1800148d0>"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"oaRLVdzPYrVG"},"source":["**What the SavedModel contains**\n","\n","Calling model.save('my_model') creates a folder named my_model, containing the following: "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HY64kmz0Xdmz","executionInfo":{"status":"ok","timestamp":1617799923456,"user_tz":-330,"elapsed":1245,"user":{"displayName":"aayush jain","photoUrl":"","userId":"06466801638325838312"}},"outputId":"ea051be3-05b3-473d-e739-87cf8c611f05"},"source":["ls my_model"],"execution_count":4,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34massets\u001b[0m/  saved_model.pb  \u001b[01;34mvariables\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MhKbKfKuZVZP"},"source":["The model architecture, and training configuration (including the optimizer, losses, and metrics) are stored in saved_model.pb. The weights are saved in the variables/ directory.|"]},{"cell_type":"markdown","metadata":{"id":"K6NakHblZwE9"},"source":["# **Keras H5 format**"]},{"cell_type":"markdown","metadata":{"id":"cm6137QXZ0Ie"},"source":["Keras also supports saving a single HDF5 file containing the model's architecture, weights values, and compile() information. It is a light-weight alternative to SavedModel."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rE5ZeCBgY3yt","executionInfo":{"status":"ok","timestamp":1617800187249,"user_tz":-330,"elapsed":1482,"user":{"displayName":"aayush jain","photoUrl":"","userId":"06466801638325838312"}},"outputId":"28d77f27-6b76-4878-9abc-bc5025988ada"},"source":["model = get_model()\n","\n","# Train the model.\n","test_input = np.random.random((128, 32))\n","test_target = np.random.random((128, 1))\n","model.fit(test_input, test_target)\n","\n","# Calling `save('my_model.h5')` creates a h5 file `my_model.h5`.\n","model.save(\"my_h5_model.h5\")\n","\n","# It can be used to reconstruct the model identically.\n","reconstructed_model = keras.models.load_model(\"my_h5_model.h5\")\n","\n","# Let's check:\n","np.testing.assert_allclose(\n","    model.predict(test_input), reconstructed_model.predict(test_input)\n",")\n","\n","# The reconstructed model is already compiled and has retained the optimizer\n","# state, so training can resume:\n","reconstructed_model.fit(test_input, test_target)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["4/4 [==============================] - 0s 3ms/step - loss: 0.2452\n","4/4 [==============================] - 0s 3ms/step - loss: 0.2329\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7ff17e63dd90>"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"6W6ds7XSaODs"},"source":["# **Limitations**\n","\n","Compared to the SavedModel format, there are two things that don't get included in the H5 file:\n","\n","External losses & metrics added via model.add_loss() & model.add_metric() are not saved (unlike SavedModel). If you have such losses & metrics on your model and you want to resume training, you need to add these losses back yourself after loading the model. Note that this does not apply to losses/metrics created inside layers via self.add_loss() & self.add_metric(). As long as the layer gets loaded, these losses & metrics are kept, since they are part of the call method of the layer.\n","The computation graph of custom objects such as custom layers is not included in the saved file. At loading time, Keras will need access to the Python classes/functions of these objects in order to reconstruct the model. See Custom objects."]},{"cell_type":"markdown","metadata":{"id":"9DAlgg89a_II"},"source":["# **Saving the architecture**"]},{"cell_type":"markdown","metadata":{"id":"h8wp3Dk8bJ3e"},"source":["The model's configuration (or architecture) specifies what layers the model contains, and how these layers are connected*. If you have the configuration of a model, then the model can be created with a freshly initialized state for the weights and no compilation information.\n","\n","*Note this only applies to models defined using the functional or Sequential apis not subclassed models.\n","\n","Configuration of a Sequential model or Functional API model\n","These types of models are explicit graphs of layers: their configuration is always available in a structured form."]},{"cell_type":"markdown","metadata":{"id":"dekYHJAGbRLW"},"source":["# **APIs**"]},{"cell_type":"markdown","metadata":{"id":"NddfjBFPbWJQ"},"source":["**get_config() and from_config()**\n","\n","**tf.keras.models.model_to_json() and tf.keras.models.model_from_json()**"]},{"cell_type":"markdown","metadata":{"id":"z1ew8R-ybtN7"},"source":["# get_config() and from_config()"]},{"cell_type":"markdown","metadata":{"id":"Nip3ywiyb4z2"},"source":["Calling **config = model.get_config()** will return a Python dict containing the configuration of the model. The same model can then be reconstructed via **Sequential.from_config(config)** (for a Sequential model) or **Model.from_config(config) (for a Functional API model).**"]},{"cell_type":"markdown","metadata":{"id":"e_TtGKmHcQN-"},"source":["**The same workflow also works for any serializable layer.**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zUl7r_M5bIUo","executionInfo":{"status":"ok","timestamp":1617800881094,"user_tz":-330,"elapsed":1361,"user":{"displayName":"aayush jain","photoUrl":"","userId":"06466801638325838312"}},"outputId":"2aaa4298-a681-42ae-fbcd-80d44aea4fd6"},"source":["layer = keras.layers.Dense(3, activation=\"relu\")\n","layer_config = layer.get_config()\n","print(layer_config)\n","new_layer = keras.layers.Dense.from_config(layer_config)\n","print(new_layer)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["{'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n","<tensorflow.python.keras.layers.core.Dense object at 0x7ff17e6845d0>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5KQm6VNjcpSa"},"source":["**Sequential model example:**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h1ZkYpdncPXg","executionInfo":{"status":"ok","timestamp":1617800941506,"user_tz":-330,"elapsed":1363,"user":{"displayName":"aayush jain","photoUrl":"","userId":"06466801638325838312"}},"outputId":"e3a24a8e-0ec7-49ff-fd8b-7b4cfa3206bb"},"source":["model = keras.Sequential([keras.Input((32,)), keras.layers.Dense(1)])\n","config = model.get_config()\n","print(config)\n","new_model = keras.Sequential.from_config(config)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["{'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 32), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'input_4'}}, {'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}]}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dwBAtmNnc3wA"},"source":["**Functional model example:**"]},{"cell_type":"code","metadata":{"id":"DKlz9NlqctCq","executionInfo":{"status":"ok","timestamp":1617800986925,"user_tz":-330,"elapsed":1243,"user":{"displayName":"aayush jain","photoUrl":"","userId":"06466801638325838312"}}},"source":["inputs = keras.Input((32,))\n","outputs = keras.layers.Dense(1)(inputs)\n","model = keras.Model(inputs, outputs)\n","config = model.get_config()\n","new_model = keras.Model.from_config(config)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M5qbIT0gdi1r"},"source":["# **to_json() and tf.keras.models.model_from_json()**"]},{"cell_type":"markdown","metadata":{"id":"QX-ZKN8FdnTX"},"source":["This is similar to get_config / from_config, except it turns the model into a JSON string, which can then be loaded without the original model class. It is also specific to models, it isn't meant for layers."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hva8z6ARc_t7","executionInfo":{"status":"ok","timestamp":1617801528246,"user_tz":-330,"elapsed":1562,"user":{"displayName":"aayush jain","photoUrl":"","userId":"06466801638325838312"}},"outputId":"c54e15a5-9d31-4626-f795-4ccd590e89c3"},"source":["model = keras.Sequential([keras.Input((32,)), keras.layers.Dense(1)])\n","json_config = model.to_json()\n","print(json_config)\n","new_model = keras.models.model_from_json(json_config)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_3\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 32], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"input_9\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_11\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 1, \"activation\": \"linear\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.4.0\", \"backend\": \"tensorflow\"}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iU8aSaYHd-8R","executionInfo":{"status":"ok","timestamp":1617801591825,"user_tz":-330,"elapsed":1354,"user":{"displayName":"aayush jain","photoUrl":"","userId":"06466801638325838312"}},"outputId":"1f044c87-f079-4bb7-c457-b3315d3a5622"},"source":["inputs = keras.Input((32,))\n","outputs = keras.layers.Dense(1)(inputs)\n","model = keras.Model(inputs, outputs)\n","json_config = model.to_json()\n","print(json_config)\n","new_model = keras.models.model_from_json(json_config)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["{\"class_name\": \"Functional\", \"config\": {\"name\": \"model_7\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 32], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"input_12\"}, \"name\": \"input_12\", \"inbound_nodes\": []}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_14\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 1, \"activation\": \"linear\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"name\": \"dense_14\", \"inbound_nodes\": [[[\"input_12\", 0, 0, {}]]]}], \"input_layers\": [[\"input_12\", 0, 0]], \"output_layers\": [[\"dense_14\", 0, 0]]}, \"keras_version\": \"2.4.0\", \"backend\": \"tensorflow\"}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_s_du0s_fdQR"},"source":["# **Saving & loading only the model's weights values**"]},{"cell_type":"markdown","metadata":{"id":"0V2Lmgngf2BZ"},"source":["## Saving & loading only the model's weights values\n","\n","You can choose to only save & load a model's weights. This can be useful if:\n","\n","- You only need the model for inference: in this case you won't need to\n","restart training, so you don't need the compilation information or optimizer state.\n","- You are doing transfer learning: in this case you will be training a new model\n","reusing the state of a prior model, so you don't need the compilation\n","information of the prior model."]},{"cell_type":"markdown","metadata":{"id":"r4Gskw48gjqZ"},"source":["### APIs for in-memory weight transfer\n","\n","Weights can be copied between different objects by using `get_weights`\n","and `set_weights`:\n","\n","* `tf.keras.layers.Layer.get_weights()`: Returns a list of numpy arrays.\n","* `tf.keras.layers.Layer.set_weights()`: Sets the model weights to the values\n","in the `weights` argument.\n","\n","\n","Examples below.\n","\n","\n","***Transfering weights from one layer to another, in memory***"]},{"cell_type":"code","metadata":{"id":"c9124df19cb2","executionInfo":{"status":"ok","timestamp":1617802035329,"user_tz":-330,"elapsed":2463,"user":{"displayName":"aayush jain","photoUrl":"","userId":"06466801638325838312"}}},"source":["def create_layer():\n","    layer = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")\n","    layer.build((None, 784))\n","    return layer\n","\n","\n","layer_1 = create_layer()\n","layer_2 = create_layer()\n","\n","# Copy weights from layer 1 to layer 2\n","layer_2.set_weights(layer_1.get_weights())"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ff7945516c7d"},"source":["***Transfering weights from one model to another model with a\n","compatible architecture, in memory***"]},{"cell_type":"code","metadata":{"id":"11005d4023d4","executionInfo":{"status":"ok","timestamp":1617802081264,"user_tz":-330,"elapsed":2638,"user":{"displayName":"aayush jain","photoUrl":"","userId":"06466801638325838312"}}},"source":["# Create a simple functional model\n","inputs = keras.Input(shape=(784,), name=\"digits\")\n","x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n","x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n","outputs = keras.layers.Dense(10, name=\"predictions\")(x)\n","functional_model = keras.Model(inputs=inputs, outputs=outputs, name=\"3_layer_mlp\")\n","\n","# Define a subclassed model with the same architecture\n","class SubclassedModel(keras.Model):\n","    def __init__(self, output_dim, name=None):\n","        super(SubclassedModel, self).__init__(name=name)\n","        self.output_dim = output_dim\n","        self.dense_1 = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")\n","        self.dense_2 = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")\n","        self.dense_3 = keras.layers.Dense(output_dim, name=\"predictions\")\n","\n","    def call(self, inputs):\n","        x = self.dense_1(inputs)\n","        x = self.dense_2(x)\n","        x = self.dense_3(x)\n","        return x\n","\n","    def get_config(self):\n","        return {\"output_dim\": self.output_dim, \"name\": self.name}\n","\n","\n","subclassed_model = SubclassedModel(10)\n","# Call the subclassed model once to create the weights.\n","subclassed_model(tf.ones((1, 784)))\n","\n","# Copy weights from functional_model to subclassed_model.\n","subclassed_model.set_weights(functional_model.get_weights())\n","\n","assert len(functional_model.weights) == len(subclassed_model.weights)\n","for a, b in zip(functional_model.weights, subclassed_model.weights):\n","    np.testing.assert_allclose(a.numpy(), b.numpy())"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bd4d08bff725"},"source":["***The case of stateless layers***\n","\n","Because stateless layers do not change the order or number of weights,\n","models can have compatible architectures even if there are extra/missing\n","stateless layers."]},{"cell_type":"code","metadata":{"id":"927dc7934d44","executionInfo":{"status":"ok","timestamp":1617802121251,"user_tz":-330,"elapsed":1824,"user":{"displayName":"aayush jain","photoUrl":"","userId":"06466801638325838312"}}},"source":["inputs = keras.Input(shape=(784,), name=\"digits\")\n","x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n","x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n","outputs = keras.layers.Dense(10, name=\"predictions\")(x)\n","functional_model = keras.Model(inputs=inputs, outputs=outputs, name=\"3_layer_mlp\")\n","\n","inputs = keras.Input(shape=(784,), name=\"digits\")\n","x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n","x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n","\n","# Add a dropout layer, which does not contain any weights.\n","x = keras.layers.Dropout(0.5)(x)\n","outputs = keras.layers.Dense(10, name=\"predictions\")(x)\n","functional_model_with_dropout = keras.Model(\n","    inputs=inputs, outputs=outputs, name=\"3_layer_mlp\"\n",")\n","\n","functional_model_with_dropout.set_weights(functional_model.get_weights())"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qS03JRqJh7II"},"source":["### APIs for saving weights to disk & loading them back\n","\n","Weights can be saved to disk by calling `model.save_weights`\n","in the following formats:\n","\n","* TensorFlow Checkpoint\n","* HDF5\n","\n","The default format for `model.save_weights` is TensorFlow checkpoint.\n","There are two ways to specify the save format:\n","\n","1. `save_format` argument: Set the value to `save_format=\"tf\"` or `save_format=\"h5\"`.\n","2. `path` argument: If the path ends with `.h5` or `.hdf5`,\n","then the HDF5 format is used. Other suffixes will result in a TensorFlow\n","checkpoint unless `save_format` is set.\n","\n","There is also an option of retrieving weights as in-memory numpy arrays.\n","Each API has its pros and cons which are detailed below."]},{"cell_type":"markdown","metadata":{"id":"N1nCmSfXjwTa"},"source":["# **TF Checkpoint format**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ku6SW7LohUiV","executionInfo":{"status":"ok","timestamp":1617802356535,"user_tz":-330,"elapsed":1151,"user":{"displayName":"aayush jain","photoUrl":"","userId":"06466801638325838312"}},"outputId":"aaa0e79c-f1ee-4412-dbf4-1461c5f5dc54"},"source":["# Runnable example\n","sequential_model = keras.Sequential(\n","    [\n","        keras.Input(shape=(784,), name=\"digits\"),\n","        keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\"),\n","        keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\"),\n","        keras.layers.Dense(10, name=\"predictions\"),\n","    ]\n",")\n","sequential_model.save_weights(\"ckpt\")\n","load_status = sequential_model.load_weights(\"ckpt\")\n","\n","# `assert_consumed` can be used as validation that all variable values have been\n","# restored from the checkpoint. See `tf.train.Checkpoint.restore` for other\n","# methods in the Status object.\n","load_status.assert_consumed()"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7ff17c4adf50>"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"5lah7rS4k5OS"},"source":["### HDF5 format\n","\n","The HDF5 format contains weights grouped by layer names.\n","The weights are lists ordered by concatenating the list of trainable weights\n","to the list of non-trainable weights (same as `layer.weights`).\n","Thus, a model can use a hdf5 checkpoint if it has the same layers and trainable\n","statuses as saved in the checkpoint.\n","\n","**Example:**"]},{"cell_type":"code","metadata":{"id":"a0H0jQm8k4oQ","executionInfo":{"status":"ok","timestamp":1617803227454,"user_tz":-330,"elapsed":1252,"user":{"displayName":"aayush jain","photoUrl":"","userId":"06466801638325838312"}}},"source":["# Runnable example\n","sequential_model = keras.Sequential(\n","    [\n","        keras.Input(shape=(784,), name=\"digits\"),\n","        keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\"),\n","        keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\"),\n","        keras.layers.Dense(10, name=\"predictions\"),\n","    ]\n",")\n","sequential_model.save_weights(\"weights.h5\")\n","sequential_model.load_weights(\"weights.h5\")"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y5lqftnKleyo"},"source":["#### Transfer learning example\n","\n","When loading pretrained weights from HDF5, it is recommended to load\n","the weights into the original checkpointed model, and then extract\n","the desired weights/layers into a new model.\n","\n","**Example:**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xgWoA52ziOIq","executionInfo":{"status":"ok","timestamp":1617803250445,"user_tz":-330,"elapsed":1394,"user":{"displayName":"aayush jain","photoUrl":"","userId":"06466801638325838312"}},"outputId":"4cf41f48-26df-4dcf-e2b0-68328e9897fb"},"source":["def create_functional_model():\n","    inputs = keras.Input(shape=(784,), name=\"digits\")\n","    x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n","    x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n","    outputs = keras.layers.Dense(10, name=\"predictions\")(x)\n","    return keras.Model(inputs=inputs, outputs=outputs, name=\"3_layer_mlp\")\n","\n","\n","functional_model = create_functional_model()\n","functional_model.save_weights(\"pretrained_weights.h5\")\n","\n","# In a separate program:\n","pretrained_model = create_functional_model()\n","pretrained_model.load_weights(\"pretrained_weights.h5\")\n","\n","# Create a new model by extracting layers from the original model:\n","extracted_layers = pretrained_model.layers[:-1]\n","extracted_layers.append(keras.layers.Dense(5, name=\"dense_3\"))\n","model = keras.Sequential(extracted_layers)\n","model.summary()"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 64)                50240     \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 64)                4160      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 5)                 325       \n","=================================================================\n","Total params: 54,725\n","Trainable params: 54,725\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GT843FIFloVQ"},"source":[""],"execution_count":null,"outputs":[]}]}